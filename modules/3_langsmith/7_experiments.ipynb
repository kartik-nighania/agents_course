{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/Users/kartik/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: 401 Error, Credentials not correct for https://typewise-206265099952.d.codeartifact.eu-central-1.amazonaws.com/pypi/tw_pypi/simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "agentic-ops\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(load_dotenv('../../.env'))\n",
    "print(os.environ['LANGSMITH_PROJECT'])\n",
    "os.environ['LANGSMITH_TRACING']=\"true\"\n",
    "os.environ['USER_AGENT'] = 'myagent'\n",
    "QDRANT_URL=\"http://localhost:6333\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "retriever = QdrantVectorStore(\n",
    "            client=QdrantClient(url=QDRANT_URL),\n",
    "            collection_name=\"documentations\",\n",
    "            embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        ).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-3.5-turbo\" # \"gpt-4o\" \"gpt-3.5-turbo\", \n",
    "MODEL_PROVIDER = \"openai\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\n",
    "        \"ls_provider\": MODEL_PROVIDER,\n",
    "        \"ls_model_name\": MODEL_NAME\n",
    "    }\n",
    ")\n",
    "def call_openai(messages: List[dict]) -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartik/Documents/auto360/agents_course/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-4o-1ff55466' at:\n",
      "https://smith.langchain.com/o/140fee06-18bc-5f8b-b369-ecfa45c28bd3/datasets/c238d5fb-3c75-4f2d-a84a-e8c667dddd25/compare?selectedSessions=8eac833f-9413-425a-9853-a224adc56740\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:57,  3.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Hugging accelerator and how do I use it?</td>\n",
       "      <td>Hugging Face Accelerate is a library designed ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Hugging Face's Accelerate is a library designe...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.027654</td>\n",
       "      <td>3e51eead-3f74-4b50-836d-2c9f270b8541</td>\n",
       "      <td>894761e2-d233-4210-99fb-1d6f54f772a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I fine-tune a pre-trained model from Hu...</td>\n",
       "      <td>To fine-tune a pre-trained model from Hugging ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To fine-tune a pre-trained model from Hugging ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.552916</td>\n",
       "      <td>10130a73-a232-4b34-b370-d37e6ddca4b6</td>\n",
       "      <td>bca83185-55d4-402a-90ce-3832bf30ea25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I use PEFT for efficient fine-tuning?</td>\n",
       "      <td>To use Parameter-Efficient Fine-Tuning (PEFT) ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To use PEFT (Parameter-Efficient Fine-Tuning) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.140116</td>\n",
       "      <td>3bf8162d-0619-41ee-b439-9347b8bf2885</td>\n",
       "      <td>33d58dfc-1d4b-44be-aa28-7a2a02604a6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I create a Gradio demo for my Hugging F...</td>\n",
       "      <td>To create a Gradio demo for your Hugging Face ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create a Gradio demo for your Hugging Face ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.545520</td>\n",
       "      <td>8720b535-614d-4b4f-9b76-1334aa1e5ec8</td>\n",
       "      <td>ea51bfa0-3754-4aaa-9e31-9365023814bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is a model card and how do I create one?</td>\n",
       "      <td>A model card is a document associated with a m...</td>\n",
       "      <td>None</td>\n",
       "      <td>A model card is a documentation file providing...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.521342</td>\n",
       "      <td>8fc42409-e3bb-4a30-bc7f-2d2ed748e465</td>\n",
       "      <td>18603791-efa1-476e-a4a1-c3b951d90696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I create a custom dataset with the Data...</td>\n",
       "      <td>To create a custom dataset with the Datasets l...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create a custom dataset with the Hugging Fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.011885</td>\n",
       "      <td>9da67a80-98c3-47ac-adb0-f7066b5fa192</td>\n",
       "      <td>8d2546b2-d78d-4500-b76d-050d5f57aa48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I quantize a model with bitsandbytes in...</td>\n",
       "      <td>To quantize a model using bitsandbytes in Hugg...</td>\n",
       "      <td>None</td>\n",
       "      <td>To quantize a model with bitsandbytes in Huggi...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.947775</td>\n",
       "      <td>beeb1981-f60c-44d3-ad66-e880852f0b59</td>\n",
       "      <td>72d28a5b-f9c2-4dd5-9255-b5e74845f03f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I enable mixed precision training with ...</td>\n",
       "      <td>To enable mixed precision training with Huggin...</td>\n",
       "      <td>None</td>\n",
       "      <td>To enable mixed precision training with Huggin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.852316</td>\n",
       "      <td>bf8f4d54-4e79-410c-bbdb-a9dbf53161bc</td>\n",
       "      <td>de34277f-f2d4-413d-9c2f-5cce6284fc59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the Hugging Face Hub?</td>\n",
       "      <td>The Hugging Face Hub is a platform that allows...</td>\n",
       "      <td>None</td>\n",
       "      <td>The Hugging Face Hub is a platform for sharing...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.904656</td>\n",
       "      <td>c8c05254-8878-4af1-94fe-677a4c023670</td>\n",
       "      <td>8e748293-f6fa-47e4-b5fa-31b5eedea979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I use Accelerate for distributed traini...</td>\n",
       "      <td>To use Accelerate for distributed training wit...</td>\n",
       "      <td>None</td>\n",
       "      <td>To use Accelerate for distributed training wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.086425</td>\n",
       "      <td>df1aeb36-777c-4028-a809-0f9cb6ed50ee</td>\n",
       "      <td>a61268bc-9ca5-470e-a195-9e1a11dc68d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How do I upload a model to the Hugging Face Hub?</td>\n",
       "      <td>You can upload a model to the Hugging Face Hub...</td>\n",
       "      <td>None</td>\n",
       "      <td>To upload a model to the Hugging Face Hub, fir...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.706481</td>\n",
       "      <td>fa6fba53-3bf8-445c-b9b3-f01cd4493d36</td>\n",
       "      <td>4cf3965a-be50-46af-b23e-00ec89db45bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the difference between Tokenizers and ...</td>\n",
       "      <td>Tokenizers and Transformers are two distinct l...</td>\n",
       "      <td>None</td>\n",
       "      <td>The Tokenizers library is specialized for fast...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.716353</td>\n",
       "      <td>fd3e7f80-2f2d-4970-986a-6de8ca83d071</td>\n",
       "      <td>87bba972-c4fa-4d82-9d32-d0b436809c9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>what is reinforcement learning?</td>\n",
       "      <td>Reinforcement learning is a machine learning p...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a type of machine learning where an agent...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.501700</td>\n",
       "      <td>0f901ab1-2d59-418f-a5aa-630a03eefe47</td>\n",
       "      <td>b029d812-1f2d-4119-9b07-3ff554b1ce3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what is natural language processing?</td>\n",
       "      <td>Natural language processing (NLP) is a field o...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a field of artificial intelligence that f...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.396691</td>\n",
       "      <td>6020a584-6d77-48e9-b715-2d3002a98621</td>\n",
       "      <td>aece138c-a175-4b19-859b-f1bc160ddcb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what is PyTorch?</td>\n",
       "      <td>PyTorch is an open-source machine learning fra...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's an open-source machine learning library p...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.165565</td>\n",
       "      <td>fe02e750-4c37-46f3-8a65-ad38e4a831f2</td>\n",
       "      <td>79f872e9-0dc4-4b56-96ad-cbddc7ce7361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what is a neural network?</td>\n",
       "      <td>A neural network is a machine learning model c...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a computational model inspired by the way...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.177516</td>\n",
       "      <td>7374adc0-d9a8-46f3-a2b1-0e7ddac8b2ab</td>\n",
       "      <td>4891dc0f-b480-4f85-bb65-857ee76f4d6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>what is TensorFlow?</td>\n",
       "      <td>TensorFlow is an open-source machine learning ...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's an open-source library for machine learni...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.343178</td>\n",
       "      <td>8af0382a-87b8-448a-8832-09778d53b263</td>\n",
       "      <td>a58cb7b1-24a6-495b-954a-98df67e99da2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"what is huggingface ? \"</td>\n",
       "      <td>Hugging Face is a company and platform often a...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Its a library for ml models\"</td>\n",
       "      <td>0</td>\n",
       "      <td>2.259877</td>\n",
       "      <td>3bab1dd9-98f2-4e4b-a60a-e39f11d942dc</td>\n",
       "      <td>644531d7-2a21-4b72-88cb-440d7af101be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-4o-1ff55466>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"test-dataset\"\n",
    "\n",
    "def is_concise_enough(reference_outputs: dict, outputs: dict) -> dict:\n",
    "    score = len(outputs[\"output\"]) < 1.5 * len(reference_outputs[\"output\"])\n",
    "    return {\"key\": \"is_concise\", \"score\": int(score)}\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-3.5-turbo-7a0d22c1' at:\n",
      "https://smith.langchain.com/o/140fee06-18bc-5f8b-b369-ecfa45c28bd3/datasets/c238d5fb-3c75-4f2d-a84a-e8c667dddd25/compare?selectedSessions=27fd8261-b6a8-4f07-a781-7ae8c544f7db\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:39,  2.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Hugging accelerator and how do I use it?</td>\n",
       "      <td>Hugging Face's Accelerate library helps users ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Hugging Face's Accelerate is a library designe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.763830</td>\n",
       "      <td>3e51eead-3f74-4b50-836d-2c9f270b8541</td>\n",
       "      <td>041db74a-3181-4915-9d56-e5923cf4de5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I fine-tune a pre-trained model from Hu...</td>\n",
       "      <td>To fine-tune a pre-trained model from Hugging ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To fine-tune a pre-trained model from Hugging ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.737913</td>\n",
       "      <td>10130a73-a232-4b34-b370-d37e6ddca4b6</td>\n",
       "      <td>faed61a8-03b0-46fd-90f1-5c6216e1845e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I use PEFT for efficient fine-tuning?</td>\n",
       "      <td>I don't have information on how to use PEFT fo...</td>\n",
       "      <td>None</td>\n",
       "      <td>To use PEFT (Parameter-Efficient Fine-Tuning) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.742571</td>\n",
       "      <td>3bf8162d-0619-41ee-b439-9347b8bf2885</td>\n",
       "      <td>6d8dee23-4a22-4f20-a047-f311a53573d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I create a Gradio demo for my Hugging F...</td>\n",
       "      <td>I don't have information on creating a Gradio ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create a Gradio demo for your Hugging Face ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004377</td>\n",
       "      <td>8720b535-614d-4b4f-9b76-1334aa1e5ec8</td>\n",
       "      <td>8b1ea574-82fe-4d9b-9639-cdde4c366630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is a model card and how do I create one?</td>\n",
       "      <td>A model card is a document that provides detai...</td>\n",
       "      <td>None</td>\n",
       "      <td>A model card is a documentation file providing...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.297387</td>\n",
       "      <td>8fc42409-e3bb-4a30-bc7f-2d2ed748e465</td>\n",
       "      <td>6f9bedd9-aa07-4e98-b98b-2c7834a25ca3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I create a custom dataset with the Data...</td>\n",
       "      <td>To create a custom dataset with the Datasets l...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create a custom dataset with the Hugging Fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.220911</td>\n",
       "      <td>9da67a80-98c3-47ac-adb0-f7066b5fa192</td>\n",
       "      <td>02ecf69e-674b-4502-95c7-b891ae340549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I quantize a model with bitsandbytes in...</td>\n",
       "      <td>To quantize a model with bitsandbytes in Huggi...</td>\n",
       "      <td>None</td>\n",
       "      <td>To quantize a model with bitsandbytes in Huggi...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.151570</td>\n",
       "      <td>beeb1981-f60c-44d3-ad66-e880852f0b59</td>\n",
       "      <td>f4935dcd-77f5-4cbf-bb55-b15e29a4ca1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I enable mixed precision training with ...</td>\n",
       "      <td>To enable mixed precision training with Huggin...</td>\n",
       "      <td>None</td>\n",
       "      <td>To enable mixed precision training with Huggin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.638544</td>\n",
       "      <td>bf8f4d54-4e79-410c-bbdb-a9dbf53161bc</td>\n",
       "      <td>6d50caee-5233-4bc3-82fc-6e4af4e8fd7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the Hugging Face Hub?</td>\n",
       "      <td>The Hugging Face Hub is a platform where you c...</td>\n",
       "      <td>None</td>\n",
       "      <td>The Hugging Face Hub is a platform for sharing...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.599100</td>\n",
       "      <td>c8c05254-8878-4af1-94fe-677a4c023670</td>\n",
       "      <td>67e9e0ed-479f-4a16-a644-30c516c373d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I use Accelerate for distributed traini...</td>\n",
       "      <td>You can use Accelerate by installing it with `...</td>\n",
       "      <td>None</td>\n",
       "      <td>To use Accelerate for distributed training wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.614899</td>\n",
       "      <td>df1aeb36-777c-4028-a809-0f9cb6ed50ee</td>\n",
       "      <td>34be303d-ea56-4e9b-b7ce-2043ab8f3a8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How do I upload a model to the Hugging Face Hub?</td>\n",
       "      <td>You can upload a model to the Hugging Face Hub...</td>\n",
       "      <td>None</td>\n",
       "      <td>To upload a model to the Hugging Face Hub, fir...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.511361</td>\n",
       "      <td>fa6fba53-3bf8-445c-b9b3-f01cd4493d36</td>\n",
       "      <td>2d82c4c1-0625-4d87-ab1a-13e39bac728c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the difference between Tokenizers and ...</td>\n",
       "      <td>Tokenizers handle the tokenization process of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The Tokenizers library is specialized for fast...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.075881</td>\n",
       "      <td>fd3e7f80-2f2d-4970-986a-6de8ca83d071</td>\n",
       "      <td>653e0fd8-810c-40cb-8eb7-443de927501c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>what is reinforcement learning?</td>\n",
       "      <td>Reinforcement learning involves casting states...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a type of machine learning where an agent...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.307586</td>\n",
       "      <td>0f901ab1-2d59-418f-a5aa-630a03eefe47</td>\n",
       "      <td>8c1e7b08-dcab-4233-84f8-80d198535255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what is natural language processing?</td>\n",
       "      <td>Natural language processing (NLP) involves tas...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a field of artificial intelligence that f...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.002657</td>\n",
       "      <td>6020a584-6d77-48e9-b715-2d3002a98621</td>\n",
       "      <td>991d7ddd-95b8-4fbf-8ee2-b61c762fa349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what is PyTorch?</td>\n",
       "      <td>PyTorch is an intermediate PyTorch model repre...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's an open-source machine learning library p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.758495</td>\n",
       "      <td>fe02e750-4c37-46f3-8a65-ad38e4a831f2</td>\n",
       "      <td>66f56646-d548-47c5-8008-af2161e42a3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what is a neural network?</td>\n",
       "      <td>A neural network is a machine learning model t...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's a computational model inspired by the way...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.377718</td>\n",
       "      <td>7374adc0-d9a8-46f3-a2b1-0e7ddac8b2ab</td>\n",
       "      <td>ea5dd3b0-64e3-45e5-a141-c4aa963282ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>what is TensorFlow?</td>\n",
       "      <td>TensorFlow is a domain-specific compiler for l...</td>\n",
       "      <td>None</td>\n",
       "      <td>It's an open-source library for machine learni...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.495980</td>\n",
       "      <td>8af0382a-87b8-448a-8832-09778d53b263</td>\n",
       "      <td>a7ff8941-1564-4845-abb5-6808b3cdab19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"what is huggingface ? \"</td>\n",
       "      <td>Hugging Face is a platform that provides libra...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Its a library for ml models\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1.657541</td>\n",
       "      <td>3bab1dd9-98f2-4e4b-a60a-e39f11d942dc</td>\n",
       "      <td>bfa2038f-3c7f-4884-aebe-797310a0e236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-3.5-turbo-7a0d22c1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO UI experiments\n",
    "* UI evaluator run\n",
    "* this local run\n",
    "* the evaluation UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=client.list_examples(dataset_name=dataset_name, as_of=\"initial dataset\"),   # We use as_of to specify a version\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"initial dataset version\"\n",
    "# )\n",
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=client.list_examples(dataset_name=dataset_name, splits=[\"Crucial Examples\"]),  # We pass in a list of Splits\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"Crucial Examples split\"\n",
    "# )\n",
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=client.list_examples(\n",
    "#         dataset_name=dataset_name, \n",
    "#         example_ids=[   # We pass in a specific list of example_ids\n",
    "#             # TODO: You will need to paste in your own example ids for this to work!\n",
    "#             \"\",\n",
    "#             \"\"\n",
    "#         ]\n",
    "#     ),\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"two specific example ids\"\n",
    "# )\n",
    "\n",
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"two repetitions\",\n",
    "#     num_repetitions=2   # This field defaults to 1\n",
    "# )\n",
    "\n",
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"concurrency\",\n",
    "#     max_concurrency=3,  # This defaults to None, so this is an improvement!\n",
    "# )\n",
    "\n",
    "# evaluate(\n",
    "#     target_function,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=[is_concise_enough],\n",
    "#     experiment_prefix=\"metadata added\",\n",
    "#     metadata={  # We can pass custom metadata for the experiment, such as the model name\n",
    "#         \"model_name\": MODEL_NAME\n",
    "#     }\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
